{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Natural Language Processing (WS 20/21)\n",
    "## Exercise Sheet 1 - Manuel Hettich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Run all the cells above the headline \"Example function calls\" to be able to use those examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "\n",
    "word_frequency_unigram = dict()\n",
    "word_frequency_bigram = dict()\n",
    "word_frequency_trigram = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1a)\n",
    "def process_line(line):\n",
    "    # Remove whitespace at the end and beginning of the sentence\n",
    "    line = line.strip()\n",
    "    # Make sentence lowercase\n",
    "    line = line.lower()\n",
    "    # Remove punctuation (Source: https://stackoverflow.com/a/60725620)\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize sentence into a list and add keywords for the beginning and the end of the sentence\n",
    "    return [\"[SOS]\"] + line.split() + [\"[EOS]\"]\n",
    "\n",
    "processed_corpus = []\n",
    "with open(\"corpus.txt\", \"rt\") as infile:\n",
    "    for line in infile:\n",
    "        # Add processed sentence to the list of all sentences in memory\n",
    "        processed_corpus += process_line(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1b)\n",
    "# Calculate frequency of each word and sequences of up to three words in the corpus\n",
    "size_of_processed_corpus = len(processed_corpus)\n",
    "for idx, word in enumerate(processed_corpus):\n",
    "    # Unigram frequency\n",
    "    if word in word_frequency_unigram:\n",
    "        word_frequency_unigram[word] += 1\n",
    "    else:\n",
    "        word_frequency_unigram[word] = 1\n",
    "    # Bigram frequency\n",
    "    if idx <= size_of_processed_corpus - 2:\n",
    "        if (word, processed_corpus[idx + 1]) in word_frequency_bigram:\n",
    "            word_frequency_bigram[(word, processed_corpus[idx + 1])] += 1\n",
    "        else:\n",
    "            word_frequency_bigram[(word, processed_corpus[idx + 1])] = 1\n",
    "    # Trigram frequency\n",
    "    if idx <= size_of_processed_corpus - 3:\n",
    "        if (word, processed_corpus[idx + 1], processed_corpus[idx + 2]) in word_frequency_trigram:\n",
    "            word_frequency_trigram[(word, processed_corpus[idx + 1], processed_corpus[idx + 2])] += 1\n",
    "        else:\n",
    "            word_frequency_trigram[(word, processed_corpus[idx + 1], processed_corpus[idx + 2])] = 1\n",
    "\n",
    "# Calculate unigram probabilities\n",
    "def word_prob_unigram(word_i):\n",
    "    # Calculate sum of all unigram word frequencies\n",
    "    sum_of_frequencies = sum(word_frequency_unigram.values())\n",
    "    return word_frequency_unigram[word_i] / sum_of_frequencies\n",
    "\n",
    "\n",
    "# Calculate bigram probabilities\n",
    "def word_prob_bigram(word_i, word_i1):\n",
    "    if (word_i1, word_i) in word_frequency_bigram:\n",
    "        return word_frequency_bigram[(word_i1, word_i)] / word_frequency_unigram[word_i1]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Calculate trigram probabilities\n",
    "def word_prob_trigram(word_i, word_i1, word_i2):\n",
    "    if (word_i2, word_i1, word_i) in word_frequency_trigram:\n",
    "        return word_frequency_trigram[(word_i2, word_i1, word_i)] / word_frequency_bigram[(word_i2, word_i1)]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1c)\n",
    "\n",
    "The numbers of parameters of these distributions scale with the number of different words N in the corpus accordingly:\n",
    "\n",
    "Unigram Model: Linear scaling because we need to calculate a probability for each word in the vocabulary.\n",
    "\n",
    "Bigram Model: # of parameters is proportional to N x N due to each possible combination of unique words although most of these will result in a 0 because most combination have never appeared in the corpus.\n",
    "\n",
    "Trigram Model: # of parameters is proportional to N x N x N with the same reasoning as for the bigram model but only for each possible triplet taken from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2a)\n",
    "def sample_unigram(*args):\n",
    "    if not args:\n",
    "        all_words_prob_unigram = [word_prob_unigram(word) for word in word_frequency_unigram.keys()]\n",
    "    else:\n",
    "        all_words_prob_unigram = args[0]\n",
    "    return np.random.choice([*word_frequency_unigram],\n",
    "                            p=all_words_prob_unigram)\n",
    "\n",
    "\n",
    "def sample_bigram(word_i1):\n",
    "    matching_bigrams = [(w_i1, w_i)\n",
    "                        for (w_i1, w_i)\n",
    "                        in word_frequency_bigram\n",
    "                        if w_i1 == word_i1]\n",
    "    return np.random.choice([w_i for (_, w_i) in matching_bigrams],\n",
    "                            p=[word_prob_bigram(w_i, word_i1)\n",
    "                               for (_, w_i)\n",
    "                               in matching_bigrams])\n",
    "\n",
    "\n",
    "def sample_trigram(word_i2, word_i1):\n",
    "    matching_trigrams = [(w_i2, w_i1, w_i)\n",
    "                         for (w_i2, w_i1, w_i)\n",
    "                         in word_frequency_trigram\n",
    "                         if w_i2 == word_i2 and w_i1 == word_i1]\n",
    "    return np.random.choice([w_i for (_, _, w_i) in matching_trigrams],\n",
    "                            p=[word_prob_trigram(w_i, word_i1, word_i2)\n",
    "                               for (_, _, w_i)\n",
    "                               in matching_trigrams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2b)\n",
    "def gen_sentence_unigram():\n",
    "    all_words_prob_unigram = [word_prob_unigram(word) for word in word_frequency_unigram.keys()]\n",
    "\n",
    "    sentence = list()\n",
    "    while True:\n",
    "        word = sample_unigram(all_words_prob_unigram)\n",
    "        if word == '[EOS]':\n",
    "            del sentence[0]\n",
    "            return ' '.join(sentence) + '.'\n",
    "        else:\n",
    "            sentence.append(word)\n",
    "\n",
    "\n",
    "def gen_sentence_bigram():\n",
    "    i = 1\n",
    "    sentence = ['[SOS]']\n",
    "    while True:\n",
    "        word = sample_bigram(sentence[i - 1])\n",
    "        if word == '[EOS]':\n",
    "            del sentence[0]\n",
    "            return ' '.join(sentence) + '.'\n",
    "        else:\n",
    "            sentence.append(word)\n",
    "            i += 1\n",
    "\n",
    "\n",
    "def gen_sentence_trigram():\n",
    "    i = 1\n",
    "    sentence = ['[SOS]']\n",
    "    while True:\n",
    "        if i >= 2:\n",
    "            word = sample_trigram(sentence[i - 2], sentence[i - 1])\n",
    "        if i == 1:\n",
    "            word = sample_bigram(sentence[i - 1])\n",
    "        if word == '[EOS]':\n",
    "            del sentence[0]\n",
    "            return ' '.join(sentence) + '.'\n",
    "        else:\n",
    "            sentence.append(word)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2c)\n",
    "\n",
    "The generated sentences based on the unigram model do not make any sense because this model generates each new word completely independent of its context. This approach does not provide a good basis for generating sentences.\n",
    "\n",
    "The bigram model delivers sentences which look like some reasonable text in English but it's still hard to find a meaningful sentence in the output. The context with only looking at a single previous word is very limited.\n",
    "\n",
    "The trigram model is sometimes able to produce meaningful sentences. The longer the sentences get, the more random they are and it gets harder to accept them as a correct sentence (as soon as we go beyond the first three words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example function calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06420179970450697"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the probability for a single word\n",
    "word_prob_unigram('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5212765957446809"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the probability for a word given a single previous word\n",
    "# Here: probability for the word 'not' given the previous word 'does'\n",
    "word_prob_bigram('not', 'does')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3081081081081081"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the probability for a word given the two previous words\n",
    "# Here: probability for the word 'the' given the two previous words 'up to'\n",
    "word_prob_trigram('the', 'to', 'up')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kind'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a sample based on unigram model\n",
    "# Caution: takes a long computation time due to the calculation of unigram probabilities for each word in the corpus\n",
    "sample_unigram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a sample based on bigram model (given a single previous word)\n",
    "sample_bigram('in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'150000000'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a sample based on trigram model (given the two previous words)\n",
    "# Here: Get a sample based on the two previous words 'up to'\n",
    "sample_trigram('up', 'to')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SOS] the of farmhouse took.\n"
     ]
    }
   ],
   "source": [
    "# Generate a sentence based on unigram model\n",
    "print(gen_sentence_unigram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353 u s phosphor screens for such unity has 43 hole crosswise through contact with television in labor unions who was.\n"
     ]
    }
   ],
   "source": [
    "# Generate a sentence based on bigram model\n",
    "print(gen_sentence_bigram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we walked down the temptation to flng himself out of its body in an areawide effort better results can be obtained from the publisher for 1680 and 2800 respectively.\n"
     ]
    }
   ],
   "source": [
    "# Generate a sentence based on trigram model\n",
    "print(gen_sentence_trigram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
